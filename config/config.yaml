

#################################### DATA-INGESTION-CONFIGURATION ################################

# creating the root folder as artifacts

artifacts_root : artifacts

# defining the data_ingestion coonfiguration

data_ingestion:
  # then again creating data_ingestion folder inside the artifacts
  root_dir : artifacts//data_ingestion
  local_data_file : artifacts//data_ingestion//Raw_data.csv


#################################### DATA-VALIDATION-CONFIGURATION ################################


data_validation:
  root_dir : artifacts//data_validation
  local_data_file : artifacts//data_ingestion//Raw_data.csv

  # when the data validation is performed on our data if it is in correct format it will return True else data validation False
  # Then only we will be starting the training pipelines only when the data is in correct format which saves the computational cost
  # Here we will be doing the schema.yaml validation

  STATUS_FILE : artifacts//data_validation//status.txt



#################################### DATA-TRANSFORMATION-CONFIGURATION ################################


data_transformation :
  root_dir : artifacts//data_transformation
  local_data_file : artifacts//data_ingestion//Raw_data.csv
  train_path : artifacts//data_transformation
  test_path : artifacts//data_transformation



model_trainer : 
  root_dir : artifacts//model_trainer
  train_data_path : artifacts//data_transformation//transformed_train_df.csv
  test_data_path : artifacts//data_transformation//transformed_test_df.csv
  # we can also save the model as pickle format
  model_name : model.joblib


#################################### MODEL-EVALUATION-CONFIGURATION ################################


model_evaluation : 
  root_dir : artifacts//model_evaluation
  test_data_path : artifacts//data_transformation//transformed_test_df.csv
  model_path : artifacts//model_trainer//model.joblib
  metric_file_name : artifacts//model_evaluation//metrics.json